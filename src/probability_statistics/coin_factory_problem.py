from typing import List, Tuple

import numpy as np
from scipy.stats import binom, uniform


def generate_posterior_samples(
    data: Tuple[int, int], n_samples: int, p_dist=None, p: float = 0.5
) -> List[float]:
    """
    generates samples to represent posterior distribution for p by
        * initialize a sample p_0
        * for each iteration
            * generate sample p_t
            * calculate acceptance ratio
            * generate random number in [0, 1]
            * use random number to either accept and update p_t or reject and not update p_t
            * append p_t to samples
    :param data: number of tosses and number of heads
    :param n_samples: number of samples to generate
    :param p_dist: prior distribution for p
    :param p: initial sample
    :return: samples
    """
    if p_dist is None:
        p_dist = uniform()

    tosses, heads = data

    samples = []
    for i in range(n_samples):
        p_next = p_dist.rvs()
        likelihood_next = binom.pmf(heads, tosses, p_next)
        prior_next = p_dist.pdf(p_next)
        likelihood = binom.pmf(heads, tosses, p)
        prior = p_dist.pdf(p)
        ratio = likelihood_next * prior_next / likelihood / prior
        u = np.random.random_sample()
        if ratio > u:
            p = p_next
        samples.append(p)
    return samples


def select_posterior_samples(
    samples: List[float], burn_in: int, lag: int
) -> List[float]:
    """
    selects samples to represent posterior distribution for p by
        * discarding first burn_in samples generated by generate_posterior_samples()
        * selecting every lag-th remaining samples
    """
    if burn_in > len(samples):
        raise ValueError(f"burn_in {burn_in} can not be more than sample size")
    samples = samples[burn_in:]
    samples = samples[::lag]
    return samples
